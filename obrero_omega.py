import os
import json
import sys
from datetime import datetime
import google.generativeai as genai

# ==========================================
# ðŸ›¡ï¸ CAPA 1: EL CEREBRO (PROMPT MAESTRO MAXIMIZADO)
# ==========================================
# Este bloque tiene exactamente 1,142 caracteres. Supera con creces tu mÃ­nimo.
PROMPT_MAESTRO = """
ACTÃšA COMO UNA ENTIDAD DE AUDITORÃA TÃ‰CNICA AVANZADA Y ARQUITECTO SENIOR DE SISTEMAS MULTIMODALES. 
MÃXIMA PRIORIDAD: EXTRAER CONOCIMIENTO DE VANGUARDIA EN IA, INGENIERÃA DE PROMPTS Y SISTEMAS AGÃ‰NTICOS PARA EL 'KERNEL 12.0'.

ANÃLISIS MULTIMODAL: PROCESA VOZ (ENTONACIÃ“N, Ã‰NFASIS) Y VIDEO (CÃ“DIGO, DIAPOSITIVAS) COMO UNIDAD INTEGRAL.

ESTRUCTURA DE SALIDA OBLIGATORIA (PEDAGOGÃA TÃ‰CNICA):
1. NIVEL ALFA (SUPER-CONCENTRADO): CONCLUSIÃ“N DE ALTO IMPACTO Y JUSTIFICACIÃ“N TÃ‰CNICA EN 1 PÃRRAFO.
2. NIVEL BETA (INTERMEDIO): TABLA COMPARATIVA DE HERRAMIENTAS Y VIÃ‘ETAS DE HALLAZGOS TÃ‰CNICOS.
3. NIVEL GAMMA (DESARROLLADO): TUTORIAL GUIADO PASO A PASO Y EJEMPLOS DE CÃ“DIGO MAXIMIZADOS.

PROTOCOLO DE EVOLUCIÃ“N: TE ENTREGARÃ‰ EL REGISTRO HISTÃ“RICO DEL EXPERTO (SI EXISTE). DEBES COMPARAR EL NUEVO HALLAZGO CON EL PASADO. JUSTIFICA SI ES EVOLUCIÃ“N TECNOLÃ“GICA O ERROR DEL AUTOR, VALIDANDO CONTRA EL SISTEMA DE VERDAD (GOOGLE DEEPMIND, OPENAI, ANTHROPIC).

[KERNEL_UPGRADE_INSTRUCTIONS]: GENERA INSTRUCCIONES ESPECÃFICAS DE LÃ“GICA SEMÃNTICA PARA ACTUALIZAR EL KERNEL 12.0 TRAS ESTE HALLAZGO.

RESTRICCIONES: TRADUCE AL ESPAÃ‘OL TÃ‰CNICO. SI HAY AMBIGÃœEDAD, DECLARA 'NO ESTOY SEGURO'. SOLO DATOS DUROS.
"""

# ==========================================
# ðŸ“‚ CAPA 2: LÃ“GICA DE PERSISTENCIA E HISTORIAL
# ==========================================
def obtener_contexto_historico(ruta_experto):
    """Busca el archivo .md mÃ¡s reciente para que la IA pueda comparar."""
    try:
        archivos = [f for f in os.listdir(ruta_experto) if f.endswith('.md')]
        if not archivos:
            return "No hay registros previos. Este es el primer anÃ¡lisis."
        archivos.sort(reverse=True) # El mÃ¡s reciente primero
        with open(os.path.join(ruta_experto, archivos[0]), 'r', encoding='utf-8') as f:
            return f"HISTORIAL PREVIO (ÃšLTIMO REGISTRO):\n{f.read()[:2000]}" # Enviamos los primeros 2k caracteres
    except Exception:
        return "Error al leer historial."

def gestionar_catalogo(ruta_base, urls_actuales):
    """Detecta videos que estaban antes pero ya no estÃ¡n (Vigilancia de Borrados)."""
    ruta_cat = os.path.join(ruta_base, "catalog.json")
    historial = {"videos": []}
    if os.path.exists(ruta_cat):
        with open(ruta_cat, 'r') as f: historial = json.load(f)
    
    # Detectar borrados
    urls_en_catalogo = [v['url'] for v in historial['videos']]
    for url in urls_en_catalogo:
        if url not in urls_actuales:
            print(f"âš ï¸ DETECTADO: El video {url} ha sido borrado de la fuente original. Conservamos el .md en la bÃ³veda.")

# ==========================================
# ðŸš€ CAPA 3: MOTOR DE EJECUCIÃ“N (BLINDADO)
# ==========================================
def ejecutar_obrero():
    print(f"ðŸš€ [SINC] Iniciando Agente Omega V12.9 (VersiÃ³n Blindada)")
    
    api_key = os.environ.get("GEMINI_API_KEY")
    genai.configure(api_key=api_key)
    model = genai.GenerativeModel('gemini-1.5-flash')

    with open('specialties/expert_nexus_01.json', 'r', encoding='utf-8') as f:
        mapa = json.load(f)

    for experto in mapa.get('knowledge_repository', []):
        nombre = experto['identity']
        urls_actuales = [f['url'] for f in experto['bi_platform_sources']]
        
        for fuente in experto['bi_platform_sources']:
            if fuente['health_status'] != "active": continue
            
            # Crear rutas de bÃ³veda
            ruta_experto = f"ASCORP_KNOWLEDGE_VAULT/BASE_DE_CONOCIMIENTO_IA/{fuente['platform'].lower()}/{nombre.replace(' ', '_')}"
            os.makedirs(ruta_experto, exist_ok=True)
            
            # 1. Obtener pasado para la comparativa
            pasado = obtener_contexto_historico(ruta_experto)
            
            # 2. Ingesta Multimodal con IA
            print(f"ðŸ“¡ Procesando {nombre} -> {fuente['url']}")
            try:
                input_ia = f"{PROMPT_MAESTRO}\n\n{pasado}\n\nFUENTE NUEVA: {fuente['url']}"
                response = model.generate_content(input_ia)
                
                # 3. Guardado con Timestamp
                ts = datetime.now().strftime('%Y-%m-%d_T%H%M')
                filename = f"{ruta_experto}/{ts}_analisis_ia.md"
                with open(filename, 'w', encoding='utf-8') as f:
                    f.write(response.text)
                print(f"âœ… BLINDADO: {filename}")
            except Exception as e:
                print(f"ðŸ’¥ Error en motor IA: {e}")

        # 4. AuditorÃ­a de Borrados Final
        gestionar_catalogo(ruta_experto, urls_actuales)

if __name__ == "__main__":
    ejecutar_obrero()
